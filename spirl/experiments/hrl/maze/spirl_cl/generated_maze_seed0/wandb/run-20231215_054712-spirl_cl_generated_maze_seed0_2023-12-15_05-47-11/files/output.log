exp_dir:	./experiments
conf_path:	spirl/configs/hrl/maze/spirl_cl/conf.py
general:
	seed:	0
	agent:	<class 'spirl.rl.components.agent.FixedIntervalHierarchicalAgent'>
	environment:	<class 'spirl.rl.envs.maze.ACRandMaze0S40Env'>
	sampler:	<class 'spirl.rl.components.sampler.ACMultiImageAugmentedHierarchicalSampler'>
	data_dir:	.
	num_epochs:	100
	max_rollout_len:	2000
	n_steps_per_epoch:	100000.0
	n_warmup_steps:	5000.0
agent:
	hl_agent:	<class 'spirl.data.maze.src.maze_agents.MazeACActionPriorSACAgent'>
	hl_agent_params:
		batch_size:	256
		replay:	<class 'spirl.rl.components.replay_buffer.UniformReplayBuffer'>
		replay_params:
			capacity:	100000.0
			dump_replay:	False
		clip_q_target:	False
		policy:	<class 'spirl.rl.policies.prior_policies.ACLearnedPriorAugmentedPIPolicy'>
		policy_params:
			action_dim:	10
			input_dim:	4
			max_action_range:	2.0
			prior_model:	<class 'spirl.models.closed_loop_spirl_mdl.ImageClSPiRLMdl'>
			prior_model_params:
				state_dim:	4
				action_dim:	2
				n_rollout_steps:	10
				kl_div_weight:	0.01
				prior_input_res:	32
				n_input_frames:	2
				cond_decode:	True
			prior_model_checkpoint:	./experiments/skill_prior_learning/maze/hierarchical_cl
		critic:	<class 'spirl.rl.components.critic.SplitObsMLPCritic'>
		critic_params:
			action_dim:	10
			input_dim:	4
			output_dim:	1
			n_layers:	2
			nz_mid:	256
			action_input:	True
			unused_obs_size:	6144
		td_schedule_params:
			p:	1.0
	ll_agent:	<class 'spirl.rl.agents.ac_agent.SACAgent'>
	ll_agent_params:
		batch_size:	256
		replay:	<class 'spirl.rl.components.replay_buffer.UniformReplayBuffer'>
		replay_params:
			capacity:	100000.0
			dump_replay:	False
		clip_q_target:	False
		policy:	<class 'spirl.rl.policies.cl_model_policies.ACClModelPolicy'>
		policy_params:
			policy_model:	<class 'spirl.models.closed_loop_spirl_mdl.ImageClSPiRLMdl'>
			policy_model_params:
				state_dim:	4
				action_dim:	2
				n_rollout_steps:	10
				kl_div_weight:	0.01
				prior_input_res:	32
				n_input_frames:	2
				cond_decode:	True
			policy_model_checkpoint:	./experiments/skill_prior_learning/maze/hierarchical_cl
			initial_log_sigma:	-50.0
			state_dim:	4
			action_dim:	2
			n_rollout_steps:	10
			kl_div_weight:	0.01
			prior_input_res:	32
			n_input_frames:	2
			cond_decode:	True
		critic:	<class 'spirl.rl.components.critic.SplitObsMLPCritic'>
		critic_params:
			action_dim:	2
			input_dim:	4
			output_dim:	1
			action_input:	True
			unused_obs_size:	10
	hl_interval:	10
	log_videos:	False
	update_hl:	True
	update_ll:	False
	device:	cuda
	env_params:
data:
	dataset_spec:
		dataset_class:	<class 'spirl.components.data_loader.GlobalSplitVideoDataset'>
		n_actions:	2
		state_dim:	4
		split:
			train:	0.9
			val:	0.1
			test:	0.0
		res:	32
		crop_rand_subseq:	True
		max_seq_len:	300
env:
	reward_norm:	1.0
	screen_height:	32
	screen_width:	32
	device:	cuda
	seed:	0
sampler:
	n_frames:	2
ckpt_path:	None
notes:	hierarchical RL on the maze env
mpi:
	rank:	0
	is_chef:	True
	num_workers:	1
Loading from: ./experiments/skill_prior_learning/maze/hierarchical_cl/weights
/home/yuhsiangwang/spirl/spirl/modules/layers.py:12: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.
  nn.init.xavier_normal(m.weight.data)
Traceback (most recent call last):
  File "spirl/rl/train.py", line 326, in <module>
    RLTrainer(args=get_args())
  File "spirl/rl/train.py", line 63, in __init__
    self.agent = self._hp.agent(self.conf.agent)
  File "/home/yuhsiangwang/spirl/spirl/rl/components/agent.py", line 326, in __init__
    super().__init__(config)
  File "/home/yuhsiangwang/spirl/spirl/rl/components/agent.py", line 211, in __init__
    self.hl_agent = self._hp.hl_agent(self._hp.overwrite(self._hp.hl_agent_params))
  File "/home/yuhsiangwang/spirl/spirl/data/maze/src/maze_agents.py", line 77, in __init__
    ActionPriorSACAgent.__init__(self, *args, **kwargs)
  File "/home/yuhsiangwang/spirl/spirl/rl/agents/prior_sac_agent.py", line 12, in __init__
    SACAgent.__init__(self, config)
  File "/home/yuhsiangwang/spirl/spirl/rl/agents/ac_agent.py", line 73, in __init__
    ACAgent.__init__(self, config)
  File "/home/yuhsiangwang/spirl/spirl/rl/agents/ac_agent.py", line 16, in __init__
    self.policy = self._hp.policy(self._hp.policy_params)
  File "/home/yuhsiangwang/spirl/spirl/rl/policies/prior_policies.py", line 145, in __init__
    LearnedPriorAugmentedPolicy.__init__(self, config)
  File "/home/yuhsiangwang/spirl/spirl/rl/policies/prior_policies.py", line 93, in __init__
    PriorAugmentedPolicy.__init__(self) #super().__init__()
  File "/home/yuhsiangwang/spirl/spirl/rl/components/policy.py", line 12, in __init__
    self.net = self._build_network()
  File "/home/yuhsiangwang/spirl/spirl/rl/policies/prior_policies.py", line 46, in _build_network
    BaseAgent.load_model_weights(net, self._hp.prior_model_checkpoint, self._hp.prior_model_epoch)
  File "/home/yuhsiangwang/spirl/spirl/rl/components/agent.py", line 160, in load_model_weights
    checkpoint_path = CheckpointHandler.get_resume_ckpt_file(epoch, checkpoint_dir)
  File "/home/yuhsiangwang/spirl/spirl/components/checkpointer.py", line 30, in get_resume_ckpt_file
    max_epoch = np.max(CheckpointHandler.get_epochs(path))
  File "/home/yuhsiangwang/spirl/spirl/components/checkpointer.py", line 20, in get_epochs
    raise ValueError("No checkpoints found at {}!".format(path))
ValueError: No checkpoints found at ./experiments/skill_prior_learning/maze/hierarchical_cl/weights!